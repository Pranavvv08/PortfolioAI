# Portfolio Neural Network for NIFTY 50 Optimization

This repository implements a deep neural network model for portfolio optimization on NIFTY 50 stocks. The model takes engineered features (statistical, liquidity, correlation) as input and predicts optimal portfolio weights.

## Features

- **Multi-layer Neural Network**: Built with TensorFlow/Keras
- **Feature Engineering**: Uses statistical, liquidity, and correlation features
- **Portfolio Optimization**: Outputs weights that sum to 1.0
- **Regularization**: Includes dropout and L2 regularization
- **Multiple Target Methods**: Risk-adjusted returns, simple returns, mean reversion
- **Backtesting**: Comprehensive performance evaluation
- **Model Persistence**: Save and load trained models

## Installation

Install the required dependencies:

```bash
pip install -r requirements.txt
```

Required packages:
- pandas>=2.0.0
- numpy>=1.21.0
- scikit-learn>=1.0.0
- tensorflow>=2.10.0
- matplotlib>=3.5.0
- seaborn>=0.11.0

## Quick Start

### 1. Basic Usage

```python
from scripts.portfolio_neural_network import PortfolioNeuralNetwork

# Initialize the model
pnn = PortfolioNeuralNetwork(
    lookback_period=5,
    prediction_horizon=1,
    random_state=42
)

# Load data
pnn.load_data()

# Prepare features and targets
features, targets = pnn.prepare_features_and_targets(
    target_method='risk_adjusted_returns'
)

# Train the model
history = pnn.train_model(features, targets, epochs=50)

# Run backtest
results = pnn.backtest_portfolio()

# Save the model
pnn.save_model('outputs/my_portfolio_model.h5')
```

### 2. Run Example Scripts

```bash
# Test basic functionality
python3 test_portfolio_nn.py

# Run comprehensive examples
python3 scripts/portfolio_examples.py

# Run the main neural network
python3 scripts/portfolio_neural_network.py
```

## Model Architecture

The neural network consists of:

1. **Input Layer**: Takes 950 engineered features
2. **Hidden Layers**: Multiple dense layers with ReLU activation
   - Layer 1: 512 neurons + Dropout (0.3)
   - Layer 2: 256 neurons + Dropout (0.3)
   - Layer 3: 128 neurons + Dropout (0.3)
3. **Output Layer**: 50 neurons (one per stock)
4. **Normalization Layer**: Softmax to ensure weights sum to 1

### Regularization Techniques

- **Dropout**: Prevents overfitting (default rate: 0.3)
- **L2 Regularization**: Weight decay (default: 0.001)
- **Early Stopping**: Monitors validation loss
- **Learning Rate Reduction**: Adaptive learning rate

## Target Variable Methods

### 1. Risk-Adjusted Returns
Creates targets based on future Sharpe-like ratios:
```python
target_method='risk_adjusted_returns'
```

### 2. Simple Returns
Uses next-period returns directly:
```python
target_method='simple_returns'
```

### 3. Mean Reversion
Based on historical mean reversion signals:
```python
target_method='mean_reversion'
```

## Data Requirements

The model expects two CSV files:

### 1. Features Data (`data/final_features.csv`)
- Date column + 950 engineered features per stock
- Features include momentum, volatility, Sharpe ratios, liquidity metrics
- Generated by running the feature engineering scripts

### 2. Returns Data (`data/log_returns.csv`)
- Date column + log returns for 50 NIFTY stocks
- Used for creating target variables and backtesting

## Backtesting

The model includes comprehensive backtesting functionality:

```python
results = pnn.backtest_portfolio()

# Access results
portfolio_return = results['metrics']['portfolio_total_return']
sharpe_ratio = results['metrics']['portfolio_sharpe']
outperformance = portfolio_return - results['metrics']['equal_weight_total_return']
```

### Performance Metrics

- **Total Returns**: Cumulative portfolio returns
- **Volatility**: Annualized portfolio volatility
- **Sharpe Ratio**: Risk-adjusted performance
- **Outperformance**: Excess return vs equal-weight benchmark

## Model Persistence

### Save Model
```python
pnn.save_model('outputs/my_model.h5')
```

Saves:
- `my_model.h5`: TensorFlow model
- `my_model_metadata.pkl`: Scalers and metadata

### Load Model
```python
pnn = PortfolioNeuralNetwork()
pnn.load_model('outputs/my_model.h5')
```

### Generate Predictions
```python
# Load latest features
features = load_latest_features()  # Your implementation

# Predict portfolio weights
weights = pnn.predict_portfolio_weights(features)
print(f"Weights sum: {weights[0].sum()}")  # Should be 1.0
```

## Advanced Usage

### Custom Architecture
```python
def custom_build_model(self, input_dim, output_dim):
    model = tf.keras.Sequential([
        tf.keras.layers.Dense(256, input_dim=input_dim, activation='relu'),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dense(output_dim, activation='linear'),
        tf.keras.layers.Lambda(lambda x: tf.nn.softmax(x))
    ])
    return model

# Replace the build_model method
pnn.build_model = lambda input_dim, output_dim, **kwargs: custom_build_model(pnn, input_dim, output_dim)
```

### Custom Training Parameters
```python
history = pnn.train_model(
    features, targets,
    test_size=0.3,
    val_size=0.2,
    epochs=100,
    batch_size=16,
    early_stopping_patience=15
)
```

## Visualization

The model generates several plots:

1. **Training History**: Loss and MAE curves
2. **Backtest Results**: Cumulative returns, weight heatmaps, performance comparison
3. **Portfolio Weights**: Distribution over time

Plots are saved to the `outputs/` directory.

## Files Structure

```
PortfolioAI/
├── data/
│   ├── final_features.csv      # Engineered features
│   ├── log_returns.csv         # Stock returns
│   └── ...
├── scripts/
│   ├── portfolio_neural_network.py    # Main neural network class
│   ├── portfolio_examples.py          # Example usage
│   └── ...
├── outputs/
│   ├── *.h5                    # Saved models
│   ├── *.png                   # Plots
│   └── ...
├── requirements.txt            # Dependencies
├── test_portfolio_nn.py       # Basic functionality test
└── README.md                  # This file
```

## Performance Notes

- **Training Time**: ~1-2 minutes for 50 epochs on CPU
- **Memory Usage**: ~500MB for the full model
- **Prediction Speed**: ~50ms per batch
- **Data Size**: Handles 100+ time periods with 950 features

## Example Results

Typical performance on NIFTY 50 data:

```
Portfolio Strategy:
  Total Return: 3032.39%
  Volatility: 398.47%
  Sharpe Ratio: 13.505

Equal Weight Benchmark:
  Total Return: 1297.30%
  Volatility: 436.14%
  Sharpe Ratio: 10.019

Outperformance: 1735.09%
```

**Note**: Results may vary based on data quality, training parameters, and market conditions.

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Submit a pull request

## License

This project is provided for educational and research purposes. Please ensure compliance with local regulations when using for trading.